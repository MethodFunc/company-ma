{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset maker v0.20\n",
    "import cv2\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import logging.config\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.config.fileConfig('logging.conf')\n",
    "logger = logging.getLogger('dataset_maker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = 'F:/MK-SD53R/2021-02-04/202'\n",
    "# SOURCE_PATH = 'D:/MKWS01/python/tf2trainer/33A(sample)/Day'\n",
    "FRAME_WIDTH, FRAME_HEIGHT = 1520, 2688\n",
    "ROI_WIDTH, ROI_HEIGHT = 150, 150\n",
    "roi = [(2, 4), (3, 4), (1, 5), (2, 5), (3, 5), (0, 6), (1, 6), (2, 6),\n",
    "       (0, 7), (1, 7), (2, 7), (0, 8), (1, 8), (0, 9), (0, 10)]\n",
    "#ROI2 = [(8, 6), (9, 7), (6, 8), (7, 8), (9, 8), (6, 9), (7, 9), (6, 10),\n",
    "#        (7, 10), (8, 10), (6, 11), (7, 11), (8, 11), (6, 12), (7, 12), (8, 12), (9, 12),\n",
    "#        (6, 13), (7, 13), (8, 13), (9, 13), (6, 14), (7, 14), (8, 14), (9, 14),\n",
    "#        (6, 15), (7, 15), (8, 15), (9, 15), (6, 16), (7, 16), (8, 16), (9, 16)]\n",
    "CATEGORIES = ['normal_day', 'normal_night']\n",
    "SAMPLE_NUMBER = 250\n",
    "validation_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 501.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for cat_item in tqdm(CATEGORIES):\n",
    "        path = ''.join([str(SOURCE_PATH).replace(\"\\\\\", \"/\"), \"/\", str(cat_item)])\n",
    "        image_file_list = fnmatch.filter(os.listdir(path), '*.jpg')\n",
    "        SAMPLE_NUMBER = min(len(image_file_list), SAMPLE_NUMBER)\n",
    "        if SAMPLE_NUMBER == 0:\n",
    "            logger.error(f'No image file exists in source path: {path}.')\n",
    "            exit()\n",
    "        elif len(image_file_list) < SAMPLE_NUMBER:\n",
    "            logger.warning(f'Number of {cat_item} image ({len(image_file_list)}) is smaller'\n",
    "                           f' than SAMPLE NUMBER({SAMPLE_NUMBER}).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 502.28it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = [], []\n",
    "\n",
    "for cat_item in tqdm(CATEGORIES):\n",
    "    path = ''.join([str(SOURCE_PATH).replace(\"\\\\\", \"/\"), \"/\", str(cat_item)])\n",
    "    image_file_list = fnmatch.filter(os.listdir(path), '*.jpg')\n",
    "    random.shuffle(image_file_list)\n",
    "\n",
    "    test_number = round(SAMPLE_NUMBER * validation_ratio)\n",
    "    train_number = SAMPLE_NUMBER - test_number\n",
    "    label = CATEGORIES.index(cat_item)\n",
    "\n",
    "    for img_file in image_file_list[:train_number]:\n",
    "        train_set.append([img_file, label])\n",
    "    for img_file in image_file_list[train_number:SAMPLE_NUMBER]:\n",
    "        test_set.append([img_file, label])\n",
    "\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18 17:38:50 dataset_maker INFO Processing training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:29<00:00, 13.42it/s]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Processing training dataset...')\n",
    "train_image, test_image, train_label, test_label = [], [], [], []\n",
    "for img_file, img_label in tqdm(train_set):\n",
    "    try:\n",
    "        path = ''.join([str(SOURCE_PATH).replace(\"\\\\\", \"/\"), \"/\", str(CATEGORIES[img_label])])\n",
    "        img_file_path = ''.join([str(path), \"/\", str(img_file)])\n",
    "        img = cv2.imread(img_file_path)\n",
    "        for (i, j) in roi:\n",
    "            x, y = i * ROI_WIDTH, j * ROI_HEIGHT\n",
    "            roi_img = img[y:y + ROI_HEIGHT, x:x + ROI_WIDTH]\n",
    "            train_image.append(roi_img)\n",
    "            train_label.append(img_label)\n",
    "    except Exception as err:\n",
    "        logger.error(f'image processing failed at {str(img_file)}')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18 17:39:43 dataset_maker INFO Processing test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.18it/s]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Processing test dataset...')\n",
    "\n",
    "for img_file, img_label in tqdm(test_set):\n",
    "    try:\n",
    "        path = ''.join([str(SOURCE_PATH).replace(\"\\\\\", \"/\"), \"/\", str(CATEGORIES[img_label])])\n",
    "        img_file_path = ''.join([str(path), \"/\", str(img_file)])\n",
    "        img = cv2.imread(img_file_path)\n",
    "        for (i, j) in roi:\n",
    "            x, y = i * ROI_WIDTH, j * ROI_HEIGHT\n",
    "            roi_img = img[y:y + ROI_HEIGHT, x:x + ROI_WIDTH]\n",
    "            test_image.append(roi_img)\n",
    "            test_label.append(img_label)\n",
    "    except Exception as err:\n",
    "        logger.error(f'image processing failed at {str(img_file)}')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-18 17:39:28 dataset_maker INFO Processing test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.22it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roi_depth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4833752fc560>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtrain_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROI_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROI_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROI_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROI_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roi_depth' is not defined"
     ]
    }
   ],
   "source": [
    "train_image = np.array(train_image).reshape(-1, ROI_HEIGHT, ROI_WIDTH, roi_depth)\n",
    "train_label = np.array(train_label)\n",
    "test_image = np.array(test_image).reshape(-1, ROI_HEIGHT, ROI_WIDTH, roi_depth)\n",
    "test_label = np.array(test_label)\n",
    "logger.info(f'Dataset Processing Finished.')\n",
    "logger.info(f'train_image: {train_image.shape}, train_label: {train_label.shape}')\n",
    "logger.info(f'test_image: {test_image.shape}, test_label: {test_label.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(SOURCE_PATH, **kwargs):\n",
    "    logger.info(f'=== Dataset Maker Start ===')\n",
    "    frame_width = kwargs['frame_width'] if 'frame_width' in kwargs else 1520\n",
    "    frame_height = kwargs['frame_height'] if 'frame_height' in kwargs else 2688\n",
    "    ROI_WIDTH = kwargs['ROI_WIDTH'] if 'ROI_WIDTH' in kwargs else 150\n",
    "    ROI_HEIGHT = kwargs['ROI_HEIGHT'] if 'ROI_HEIGHT' in kwargs else 150\n",
    "    roi_depth = kwargs['roi_depth'] if 'roi_depth' in kwargs else 3\n",
    "    SAMPLE_NUMBER = kwargs['SAMPLE_NUMBER'] if 'SAMPLE_NUMBER' in kwargs else 1000\n",
    "    validation_ratio = kwargs['validation_ratio'] if 'validation_ratio' in kwargs else 0.3\n",
    "    if 'roi' in kwargs:\n",
    "        roi = kwargs['roi']\n",
    "    else:\n",
    "        # 수정 필요\n",
    "        roi = []\n",
    "\n",
    "    if 'CATEGORIES' in kwargs:\n",
    "        CATEGORIES = kwargs['CATEGORIES']\n",
    "    else:\n",
    "        # 수정 필요\n",
    "        CATEGORIES = ['Dry', 'Wet']\n",
    "\n",
    "    for cat_item in CATEGORIES:\n",
    "        path = ''.join([str(SOURCE_PATH).replace(\"\\\\\", \"/\"), \"/\", str(cat_item)])\n",
    "        image_file_list = fnmatch.filter(os.listdir(path), '*.jpg')\n",
    "        SAMPLE_NUMBER = min(len(image_file_list), SAMPLE_NUMBER)\n",
    "        if SAMPLE_NUMBER == 0:\n",
    "            logger.error(f'No image file exists in source path: {path}.')\n",
    "            exit()\n",
    "        elif len(image_file_list) < SAMPLE_NUMBER:\n",
    "            logger.warning(f'Number of {cat_item} image ({len(image_file_list)}) is smaller'\n",
    "                           f' than SAMPLE NUMBER({SAMPLE_NUMBER}).')\n",
    "\n",
    "    train_set, test_set = [], []\n",
    "    for cat_item in CATEGORIES:\n",
    "        path = ''.join([str(SOURCE_PATH).replace(\"\\\\\", \"/\"), \"/\", str(cat_item)])\n",
    "        image_file_list = fnmatch.filter(os.listdir(path), '*.jpg')\n",
    "        random.shuffle(image_file_list)\n",
    "\n",
    "        test_number = round(SAMPLE_NUMBER * validation_ratio)\n",
    "        train_number = SAMPLE_NUMBER - test_number\n",
    "        label = CATEGORIES.index(cat_item)\n",
    "\n",
    "        for img_file in image_file_list[:train_number]:\n",
    "            train_set.append([img_file, label])\n",
    "        for img_file in image_file_list[train_number:SAMPLE_NUMBER]:\n",
    "            test_set.append([img_file, label])\n",
    "\n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "\n",
    "    train_image, test_image, train_label, test_label = [], [], [], []\n",
    "    logger.info(f'Processing training dataset...')\n",
    "\n",
    "    for img_file, img_label in train_set:\n",
    "        try:\n",
    "            path = ''.join([str(SOURCE_PATH).replace(\"\\\\\", \"/\"), \"/\", str(CATEGORIES[img_label])])\n",
    "            img_file_path = ''.join([str(path), \"/\", str(img_file)])\n",
    "            img = cv2.imread(img_file_path)\n",
    "            for (i, j) in roi:\n",
    "                x, y = i * ROI_WIDTH, j * ROI_HEIGHT\n",
    "                roi_img = img[y:y + ROI_HEIGHT, x:x + ROI_WIDTH]\n",
    "                train_image.append(roi_img)\n",
    "                train_label.append(img_label)\n",
    "        except Exception as err:\n",
    "            logger.error(f'image processing failed at {str(img_file)}')\n",
    "            pass\n",
    "\n",
    "    logger.info(f'Processing test dataset...')\n",
    "    for img_file, img_label in test_set:\n",
    "        try:\n",
    "            path = ''.join([str(SOURCE_PATH).replace(\"\\\\\", \"/\"), \"/\", str(CATEGORIES[img_label])])\n",
    "            img_file_path = ''.join([str(path), \"/\", str(img_file)])\n",
    "            img = cv2.imread(img_file_path)\n",
    "            for (i, j) in roi:\n",
    "                x, y = i * ROI_WIDTH, j * ROI_HEIGHT\n",
    "                roi_img = img[y:y + ROI_HEIGHT, x:x + ROI_WIDTH]\n",
    "                test_image.append(roi_img)\n",
    "                test_label.append(img_label)\n",
    "        except Exception as err:\n",
    "            logger.error(f'image processing failed at {str(img_file)}')\n",
    "            pass\n",
    "\n",
    "    train_image = np.array(train_image).reshape(-1, ROI_HEIGHT, ROI_WIDTH, roi_depth)\n",
    "    train_label = np.array(train_label)\n",
    "    test_image = np.array(test_image).reshape(-1, ROI_HEIGHT, ROI_WIDTH, roi_depth)\n",
    "    test_label = np.array(test_label)\n",
    "    logger.info(f'Dataset Processing Finished.')\n",
    "    logger.info(f'train_image: {train_image.shape}, train_label: {train_label.shape}')\n",
    "    logger.info(f'test_image: {test_image.shape}, test_label: {test_label.shape}')\n",
    "    return (train_image, train_label), (test_image, test_label)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_dataset(SOURCE_PATH=SOURCE_PATH, roi=ROI1, SAMPLE_NUMBER=SAMPLE_NUMBER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
